{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Statistics Fundamentals\n",
    "\n",
    "_Instructor:_ Alexander Egorenkov (DC), Amy Roberts (NYC) Tim Book, General Assembly DC_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "## Learning Objectives\n",
    "- **Linear algebra:** Dot products, matrix multiplications, and vector norms by hand and using NumPy.\n",
    "- **Summary statistics:** Using NumPy and Pandas: mean, median, mode, max, min, quartile, inter-quartile range, variance, standard deviation, and correlation.\n",
    "- **Discover trends:** Using basic summary statistics and viz.\n",
    "- **Bias/variance tradeoff:** Describe the bias and variance of statistical estimators.\n",
    "- **Identify a normal distribution** within a data set using summary statistics and data visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Linear Algebra Review](#linear-algebra-review)\n",
    "    - [Scalars, Vectors, and Matrices](#scalars-vectors-and-matrices)\n",
    "\t- [Basic Matrix Algebra](#basic-matrix-algebra)\n",
    "\t- [Dot Product](#dot-product)\n",
    "\t- [Matrix Multiplication](#matrix-multiplication)\n",
    "\t- [Vector Norm](#vector-norm)\n",
    "- [Linear Algebra Applications to Machine Learning](#linear-algebra-applications-to-machine-learning)\n",
    "    - [Code-Along: Examining the Cars Data Set](#codealong-examining-the-cars-dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:41.295575Z",
     "start_time": "2021-12-06T18:10:35.932368Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics # Did you catch this is new? \n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# This makes sure that graphs render in your notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"where-are-we-in-the-data-science-workflow\"></a>\n",
    "## Where Are We in the Data Science Workflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Science Workflow](./assets/images/data-science-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-algebra-review\"></a>\n",
    "## Linear Algebra Review\n",
    "---\n",
    "**Objective:** Compute dot products, matrix multiplications, and vector norms by hand and using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"why-linear-algebra\"></a>\n",
    "### Why Use Linear Algebra in Data Science?\n",
    "\n",
    "- Linear models are efficient and well understood. They can often closely approximate nonlinear solutions, and they scale to high dimensions without difficulty.\n",
    "\n",
    "\n",
    "- **Linear models are all based on linear algebra**, so we should know that too.\n",
    "\n",
    "\n",
    "- Furthermore, even the complicated models rely on the basic models, which in turn rely heavily on linear algebra.\n",
    "\n",
    "\n",
    "- Although we do not have time in this course to comprehensively discuss linear algebra, you may want to take time to understand it better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scalars-vectors-and-matrices\"></a>\n",
    "### Scalars, Vectors, and Matrices\n",
    "\n",
    "<img src=\"assets/images/scalars-vectors-matrices.png\">\n",
    "\n",
    "\n",
    "A **scalar** is a single number. \n",
    "- Symbols that are lowercase single letters refer to scalars. For example, the symbols $a$ and $v$ are scalars that might refer to arbitrary numbers such as $5.328$ or $7$. \n",
    "\n",
    "- An example scalar would be: $a$\n",
    "\n",
    "- It's usually easy to consider vectors as either a $1 \\times n$ or $n \\times 1$ \"row\" or \"column\" vector, where convenient.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "A **vector** is an ordered sequence of numbers, **like a list**. \n",
    "- Unlike a Python list, a vector can only be numeric. It can be a row or a column.\n",
    "- Here, symbols that are lowercase single letters with an arrow — such as $\\vec{u}$ — refer to vectors. An example vector would be:\n",
    "\n",
    "$$\\vec{u} = \\left[ \\begin{array}{c}\n",
    "1&3&7\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:45.565172Z",
     "start_time": "2021-12-06T18:10:45.548753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a vector using np.array. Numpy arrays are data structures in the numpy module, \n",
    "# this one operates like a list. \n",
    "# But the difference is how numpy works with this data structure.\n",
    "\n",
    "u = np.array([1, 3, 7])\n",
    "print(u)\n",
    "print(np.sum(u))\n",
    "print(u[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An $m$ x $n$ **matrix** is a rectangular array of numbers with $m$ rows and $n$ columns. Each number in the matrix is an entry. Entries can be denoted $a_{ij}$, where $i$ denotes the row number and $j$ denotes the column number. Note that, because each entry $a_{ij}$ is a lowercase single letter, a matrix is an array of scalars:\n",
    "\n",
    "$$\\mathbf{A}= \\left[ \\begin{array}{c}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n}  \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n}  \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{array} \\right]$$\n",
    "\n",
    "Matrices are referred to using bold uppercase letters, such as $\\mathbf{A}$. A bold font face is used to distinguish matrices from sets. (Sometimes, not always)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:47.733019Z",
     "start_time": "2021-12-06T18:10:47.724746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a matrix using np.array.\n",
    "m = np.array([[1, 3, 7], [4, 6, 3], [2, 5, 6]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in Python, a matrix is just a list of lists converted to numpy arrays(or a group of vectors)! **In fact, a vector is also matrix!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrays are More Efficient than Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:49.350447Z",
     "start_time": "2021-12-06T18:10:49.344260Z"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(u)\n",
    "print(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:49.967064Z",
     "start_time": "2021-12-06T18:10:49.946997Z"
    }
   },
   "outputs": [],
   "source": [
    "a = %timeit -n 10000 u[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:10:50.691743Z",
     "start_time": "2021-12-06T18:10:50.476665Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 10000 s[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basic-matrix-algebra\"></a>\n",
    "### Basic Matrix Algebra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition and Subtraction\n",
    "Vector **addition** is straightforward. If two vectors are of equal dimensions (The vectors are shown here as column vectors for convenience only):\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right],  \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:11:01.123401Z",
     "start_time": "2021-12-06T18:11:01.120398Z"
    }
   },
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{v} + \\vec{w} =\n",
    "\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] + \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "1+1 \\\\\n",
    "3+0 \\\\\n",
    "7+1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "8\n",
    "\\end{array} \\right]\n",
    "$\n",
    "\n",
    "(Subtraction is similar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:38.270602Z",
     "start_time": "2021-12-06T18:17:38.218295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the vectors together with +.\n",
    "v + w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:39.005490Z",
     "start_time": "2021-12-06T18:17:38.997640Z"
    }
   },
   "outputs": [],
   "source": [
    "# now using numpy (np.sum)\n",
    "np.sum([v,w], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:31:25.157116Z",
     "start_time": "2020-05-04T17:31:25.150167Z"
    }
   },
   "source": [
    "**Classroom Question**: What happens when **axis=1**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:32:04.884922Z",
     "start_time": "2020-05-04T17:32:04.878938Z"
    }
   },
   "source": [
    "**Classroom Exercise**:\n",
    "Subtract the vectors.  Write it out by hand and then allow Python to do the work.\n",
    "\n",
    "Use `.subtract()` in the `numpy` module. If needed, use `shift-tab` to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:42.197704Z",
     "start_time": "2021-12-06T18:17:42.191325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subtract the vectors using the two methods similar to those we just used for addition\n",
    "np.subtract(v,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:42.702163Z",
     "start_time": "2021-12-06T18:17:42.696031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use an alternative method to perform vector subtraction.\n",
    "v-w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalar Multiplication\n",
    "We scale a vector with **scalar multiplication**, multiplying a vector by a scalar (single quantity):\n",
    "\n",
    "$ 2 \\cdot \\vec{v} = 2\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\cdot 1 \\\\\n",
    "2 \\cdot 3 \\\\\n",
    "2 \\cdot 7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "6 \\\\\n",
    "14\n",
    "\\end{array} \\right]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:43.659681Z",
     "start_time": "2021-12-06T18:17:43.654347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multiply v by 2.\n",
    "2*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:44.345858Z",
     "start_time": "2021-12-06T18:17:44.331229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multiply w and v\n",
    "w*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dot-product\"></a>\n",
    "### Dot Product\n",
    "The **dot product** of two _n_-dimensional vectors is:\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} =\\sum _{i=1}^{n}v_{i}w_{i}=v_{1}w_{1}+v_{2}w_{2}+\\cdots +v_{n}w_{n} $\n",
    "\n",
    "So, if:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right], \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} = 1 \\cdot 1 + 3 \\cdot 0 + 7 \\cdot 1 = 8 $\n",
    "\n",
    "_Tim Note:_ When considering vectors as \"column vectors\", you will often see a dot product written as $\\mathbf{v}^T\\mathbf{w}$. In more pure-math based literature, you might even see $\\langle v, w \\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:45.157240Z",
     "start_time": "2021-12-06T18:17:45.149523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the dot product of v and w using np.dot.\n",
    "np.dot(v,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:45.751572Z",
     "start_time": "2021-12-06T18:17:45.744931Z"
    }
   },
   "outputs": [],
   "source": [
    "# try the .dot() method on v to do the same\n",
    "# How could you have found this option?\n",
    "v.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"matrix-multiplication\"></a>\n",
    "### Matrix Multiplication\n",
    "**Matrix multiplication**, $\\mathbf{AB}$, is valid when the left matrix has the same number of columns as the right matrix has rows. Each entry is the dot product of corresponding row and column vectors.\n",
    "\n",
    "![](assets/images/matrix-multiply-a.gif)\n",
    "(Image: mathisfun.com)\n",
    "\n",
    "\n",
    "![](assets/images/matrix-multiplication-song.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product illustrated above is: $1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11 = 58$. **Can you compute the rest of the dot products by hand?**\n",
    "\n",
    "If the product is the $2$ x $2$ matrix $\\mathbf{C}$, then:\n",
    "\n",
    "+ Matrix entry $c_{12}$ (its FIRST row and SECOND column) is the dot product of the FIRST row of $\\mathbf{A}$ and the SECOND column of $\\mathbf{B}$.\n",
    "\n",
    "+ Matrix entry $c_{21}$ (its SECOND row and FIRST column) is the dot product of the SECOND row of $\\mathbf{A}$ and the FIRST column of $\\mathbf{B}$.\n",
    "\n",
    "**Lets compute the example above, with the $2$ x $3$ matrix multiplied by $3$ x $2$ matrix, which results in a $2$ x $2$ matrix. Can you see why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:48.289011Z",
     "start_time": "2021-12-06T18:17:48.270687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiply the two above matrices\n",
    "\n",
    "#Make them first\n",
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "B = np.array([[7,8],[9,10],[11,12]])\n",
    "\n",
    "#now multiply! \n",
    "# Someone tell me what goes here to multply these to matrices (order matters)\n",
    "\n",
    "C = np.dot(A,B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:17:49.444509Z",
     "start_time": "2021-12-06T18:17:49.439069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset C to show the value in the first row and second column (upper right value!)\n",
    "C[0][1] \n",
    "\n",
    "# or\n",
    "\n",
    "C[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"n-dimensional-space\"></a>\n",
    "### N-Dimensional Space\n",
    "\n",
    "We often refer to vectors as elements of an $n$-dimensional space. The symbol $\\mathbb{R}$ refers to the set of all real numbers (written in uppercase \"blackboard bold\" font). Because this contains all reals, $3$ and $\\pi$ are **contained in** $\\mathbb{R}$. We often write this symbolically as $3 \\in \\mathbb{R}$ and $\\pi \\in \\mathbb{R}$.\n",
    "\n",
    "To get the set of all pairs of real numbers, we would essentially take the product of this set with itself (called the Cartesian product) — $\\mathbb{R}$ x $\\mathbb{R}$, abbreviated as $\\mathbb{R}^2$. This set — $\\mathbb{R}^2$ — contains all pairs of real numbers, so $(1, 3)$ is **contained in** this set. We write this symbolically as $(1, 3) \\in \\mathbb{R}^2$.\n",
    "\n",
    "+ In 2-D space ($\\mathbb{R}^2$), a point is uniquely referred to using two coordinates: $(1, 3) \\in \\mathbb{R}^2$.\n",
    "+ In 3-D space ($\\mathbb{R}^3$), a point is uniquely referred to using three coordinates: $(8, 2, -3) \\in \\mathbb{R}^3$.\n",
    "+ In $n$-dimensional space ($\\mathbb{R}^n$), a point is uniquely referred to using $n$ coordinates.\n",
    "\n",
    "Note that these coordinates of course are isomorphic to our vectors! After all, coordinates are ordered sequences of numbers, just as we define vectors to be ordered sequences of numbers. So, especially in machine learning, we often visualize vectors of length $n$ as points in $n$-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vector-norm\"></a>\n",
    "### Vector Norm \n",
    "\n",
    "The **magnitude** of a vector, $\\vec{v} \\in \\mathbb{R}^{n}$, can be interpreted as its length in $n$-dimensional space. Therefore it is calculable via the Euclidean distance from the origin:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "v_{1} \\\\\n",
    "v_{2} \\\\\n",
    "\\vdots \\\\\n",
    "v_{n}\n",
    "\\end{array} \\right]$\n",
    "\n",
    "then $\\| \\vec{v} \\| = \\sqrt{v_{1}^{2} + v_{2}^{2} + ... + v_{n}^{2}} = \\sqrt{\\vec{v}^T\\vec{v}}$\n",
    "\n",
    "E.g. if $\\vec{v} = \n",
    "\\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{array} \\right]$, then $\\| \\vec{v} \\| = \\sqrt{3^{2} + 4^{2}} = 5$\n",
    "\n",
    "This is also called the vector **norm**. You will often see this used in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:01.242139Z",
     "start_time": "2021-12-06T18:18:01.215924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the norm of the vector x with np.linalg.norm.\n",
    "x = np.array([3,4])\n",
    "\n",
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-algebra-applications-to-machine-learning\"></a>\n",
    "## Linear Algebra Applications to Machine Learning\n",
    "---\n",
    "\n",
    "Linear Algebra will give you better intuition for machine learning algorithms and see them beyond \"black boxes\".  Models have parameters, or hyperparameters that you can tune, and understanding the inner workings can help you refine your models.\n",
    "\n",
    "You can also code algorithms from scratch, if you choose to become more advanced.\n",
    "\n",
    "<a id=\"distance-between-actual-values-and-predicted-values\"></a>\n",
    "### Distance Between Actual Values and Predicted Values\n",
    "We often need to know the difference between predicted values and actual values. \n",
    "\n",
    "![](assets/images/vector-norms.png)\n",
    "\n",
    "\n",
    "#### L² Norm (Least Squares)\n",
    "Most commonly, we use the **L²** norm, which is the sum of the squared values.  In 2-D space, we compute this as:\n",
    "$$ L^2 norm = \\|\\vec{actual} - \\vec{predicted} \\| = \\sqrt{(actual_1 - predicted_1)^2 + (actual_2 - predicted_2)^2 ... + (actual_n - predicted_n)^2}$$\n",
    "\n",
    "Note that this is just the **straight-line distance** or **as-the-crow-flies distance** between the actual point and the predicted point.\n",
    "\n",
    "\n",
    "#### L¹ Norm (Least Absolute Deviations)\n",
    "Another less used method is the **L¹** norm, aka **taxicab distance** because it describes the number of blocks to travel to reach the destination.\n",
    "\n",
    "$$ L^1 norm = \\|\\vec{actual} - \\vec{predicted} \\| = |(actual_1 - predicted_1)| + |(actual_2 - predicted_2)| ... + |(actual_n - predicted_n)| $$\n",
    "\n",
    "\n",
    "![](assets/images/L1-vs-L2-properties1.png)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Mean Absolute Error\n",
    "MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. All individual differences have equal weight.\n",
    "\n",
    "$$MAE = \\frac{1} {n} \\| \\hat{y}(\\mathbf{X}) - \\vec{y} \\|$$\n",
    "\n",
    "\n",
    "<a id=\"mean-squared-error\"></a>\n",
    "### Mean Squared Error\n",
    "Another method for measuring distance, or error between predicted and actual, is the mean of the squared errors.  **This is often used to measure the quality of regression models.** Where $\\hat{y}(\\mathbf{X})$ is a vector of predicted values (a function of the data matrix $\\mathbf{X}$) and $\\vec{y}$ is the actual values:\n",
    "\n",
    "$$MSE = \\frac{1} {n} ( \\hat{y}(\\mathbf{X}) - \\vec{y} )^2$$\n",
    "\n",
    "\n",
    "\n",
    "### Root Mean Squared Error\n",
    "Another similar method for measuring distance, or error between predicted and actual, is the square root of the mean of the squared errors.  **This is another common method to measure the quality of regression models.** Where $\\hat{y}(\\mathbf{X})$ is a vector of predicted values (a function of the data matrix $\\mathbf{X}$) and $\\vec{y}$ is the actual values:\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1} {n} ( \\hat{y}(\\mathbf{X}) - \\vec{y} )^2}$$\n",
    "\n",
    "\n",
    "Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful than MAE and MSE when large errors are not desired.\n",
    "\n",
    "<a id=\"least-squares\"></a>\n",
    "### Least Squares\n",
    "Regression models use least squares to optimize the fit of the model, and are based on the following form:\n",
    "\n",
    "$$\\min \\| \\hat{y}(\\mathbf{X}) - \\vec{y} \\|^2$$\n",
    "\n",
    "The goal is to minimize the distance between model predictions and actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in [scikit-learn](http://scikit-learn.org/stable/modules/linear_model.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"codealong-examining-the-cars-dataset\"></a>\n",
    "### Follow-Along: Examining the Cars dataset\n",
    "---\n",
    "\n",
    "This is a follow-along vs a code-along for the sake of time so we can get back to statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the Motor Trend Cars data. \n",
    "\n",
    "**Data Source**: https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\n",
    "\n",
    "**Description**\n",
    "The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\n",
    "\n",
    "**Format**\n",
    "A data frame with 32 observations on 11 (numeric) variables.\n",
    "\n",
    "- **mpg**\tMiles/(US) gallon\n",
    "- **cyl**\tNumber of cylinders\n",
    "- **disp**\tDisplacement (cu.in.)\n",
    "- **hp**\tGross horsepower\n",
    "- **drat**\tRear axle ratio\n",
    "- **wt**\tWeight (1000 lbs)\n",
    "- **qsec**\t1/4 mile time\n",
    "- **vs**\tEngine (0 = V-shaped, 1 = straight)\n",
    "- **am**\tTransmission (0 = automatic, 1 = manual)\n",
    "- **gear**\tNumber of forward gears\n",
    "- **carb**\tNumber of carburetors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:05.605426Z",
     "start_time": "2021-12-06T18:18:05.489352Z"
    }
   },
   "outputs": [],
   "source": [
    "mtcars = pd.read_csv('datasets/mtcars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we were trying to predict mpg of a car.  Lets create 2 random columns, *predicted mpg* and *predicted_mpg_2* , that we will assume were predicted with 2 different machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:06.606109Z",
     "start_time": "2021-12-06T18:18:06.556420Z"
    }
   },
   "outputs": [],
   "source": [
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic values for each prediction (demo purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:23.420357Z",
     "start_time": "2021-12-06T18:18:23.412983Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(99)  # this ensures repeatability of results - our results should be the same.\n",
    "mtcars['predicted_mpg'] = np.random.randint(15, 30, mtcars.shape[0])\n",
    "mtcars['predicted_mpg_2'] = np.random.randint(18, 26, mtcars.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:24.162243Z",
     "start_time": "2021-12-06T18:18:24.144635Z"
    }
   },
   "outputs": [],
   "source": [
    "mtcars.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the dimensions of the DataFrame using the `.shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:26.812185Z",
     "start_time": "2021-12-06T18:18:26.805341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preview data dimensions.\n",
    "mtcars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the data types of the columns using the `.dtypes` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:28.333252Z",
     "start_time": "2021-12-06T18:18:28.324710Z"
    }
   },
   "outputs": [],
   "source": [
    "# What are the column data types?\n",
    "mtcars.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull up descriptive statistics for each variable using the built-in `.describe()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:29.971149Z",
     "start_time": "2021-12-06T18:18:29.867289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull up descriptive statistics for mpg, predicted_mpg and predicted_mpg_2\n",
    "mtcars[['mpg','predicted_mpg','predicted_mpg_2']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Euclidean distance between the predicted columns and actual column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:37.572069Z",
     "start_time": "2021-12-06T18:18:37.556272Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#L2 Norm aka Euclidean Distance aka Straight-Line Distance\n",
    "print('Model 1 L2 Norm:', np.linalg.norm(mtcars['mpg']-mtcars['predicted_mpg']))\n",
    "\n",
    "print('Model 2 L2 Norm:', np.linalg.norm(mtcars['mpg']-mtcars['predicted_mpg_2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "\n",
    "#### 1. Going the Distance\n",
    "\n",
    "Calculate the L1 Norm for each prediction.  Look at the help for np.linalg.norm, and specifically the **ord** parameter. (hint:L**1**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:39.097238Z",
     "start_time": "2021-12-06T18:18:39.091866Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model 1 L1 Norm:', np.linalg.norm(mtcars['mpg']-mtcars['predicted_mpg'], ord=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:43.482974Z",
     "start_time": "2021-12-06T18:18:43.476616Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model 2 L1 Norm:', np.linalg.norm(mtcars['mpg']-mtcars['predicted_mpg_2'], ord=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Calculate the MAE using numpy.  (hint: nest np.abs into np.mean and np.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:45.644129Z",
     "start_time": "2021-12-06T18:18:45.636700Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model 1 MAE:', np.mean(np.abs(mtcars['mpg']-mtcars['predicted_mpg'])))\n",
    "print('Model 2 MAE:', np.mean(np.abs(mtcars['mpg']-mtcars['predicted_mpg_2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Calculate the MSE using numpy.  (hint: use np.mean and np.square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:18:51.158572Z",
     "start_time": "2021-12-06T18:18:51.146935Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model 1 MSE:', np.mean(np.square(mtcars.mpg-mtcars.predicted_mpg)))\n",
    "print('Model 2 MSE:', np.mean(np.square(mtcars.mpg-mtcars.predicted_mpg_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: What are the units of this error?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calculate the RMSE using numpy.  (hint: use the MSE calculation and take the square root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T18:21:09.738264Z",
     "start_time": "2021-12-06T18:21:09.733182Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Model 1 RMSE:', np.sqrt(np.mean(np.square(mtcars.mpg-mtcars.predicted_mpg))))\n",
    "print('Model 2 RMSE:', np.sqrt(np.mean(np.square(mtcars.mpg-mtcars.predicted_mpg_2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: What are the units of this error?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Based on these metrics, which of these 2 simple models is better at explaining the behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
